{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from slugify import slugify\n",
    "\n",
    "import json, math\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of Fields: 75\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# List of implementations to check\n",
    "implementations = [\n",
    "    \"parametric-gpt\",\n",
    "    \"parametric-gemini\",\n",
    "    \"parametric-claude\",\n",
    "    \"parametric-llama\",\n",
    "    \"parametric-qwen\",\n",
    "\n",
    "    \"retrieval-gpt\",\n",
    "    \"retrieval-gemini\",\n",
    "    \"retrieval-claude\",\n",
    "    \"retrieval-qwen\",\n",
    "    \"retrieval-openscholar\",\n",
    "\n",
    "    \"agentic-openscholar\",\n",
    "    \"agentic-perplexity-web-search\",\n",
    "    \"agentic-perplexity-web-search-reasoning\",\n",
    "    \"agentic-openai-web-search\",\n",
    "    \"agentic-gemini-web-search\",\n",
    "    \"agentic-anthropic-web-research\",\n",
    "    \"agentic-perplexity-deep-research\",\n",
    "    \"agentic-openai-deep-research\",\n",
    "]\n",
    "\n",
    "# Base directory where all field folders are located\n",
    "base_dir = Path(\"/nlp/data/academic_pdfs/multi_domain_testbed/systems_comparison\")\n",
    "\n",
    "fields = [d for d in base_dir.iterdir() if d.is_dir()]\n",
    "fields = [base_dir / f for f in fields]\n",
    "print(f\"Num of Fields: {len(fields)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper function to extract rubric coverage Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_path = \"/nlp/data/academic_pdfs/multi_domain_testbed/data_release/researchqa/test.json\"\n",
    "with open(test_set_path, \"r\") as f:\n",
    "    test_set = json.load(f)\n",
    "id_to_data_test = {data['id']: data for data in test_set}\n",
    "id_to_domain = {data['id']: data['general_domain'] for data in test_set}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_text_to_score(text):\n",
    "    text_to_score = {\n",
    "        'Not at all': 1, \n",
    "        'Barely': 2, \n",
    "        'Moderately': 3, \n",
    "        'Mostly': 4, \n",
    "        'Completely': 5\n",
    "    }\n",
    "    return text_to_score[text]\n",
    "\n",
    "\n",
    "def normalize_5scale(x):\n",
    "    return (x - 1) / 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leaderboard Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ref: https://colab.research.google.com/drive/1RAWb22-PFNI-X1gPVzc927SGUdfr6nsR?usp=sharing#scrollTo=C5H_wlbqGwCJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_split_path = Path(\"/nlp/data/academic_pdfs/multi_domain_testbed/data_release/researchqa/test.json\")\n",
    "with open(test_split_path, encoding=\"utf-8\") as f:\n",
    "    test_set = json.load(f)\n",
    "\n",
    "id_to_test_data = {item['id']: item for item in test_set} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>implementation_A</th>\n",
       "      <th>implementation_B</th>\n",
       "      <th>judge</th>\n",
       "      <th>judge_swapped</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>174539434903306044-s15</td>\n",
       "      <td>agentic-anthropic-web-research</td>\n",
       "      <td>retrieval-claude</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>174539434903306044-s15</td>\n",
       "      <td>agentic-openai-deep-research</td>\n",
       "      <td>retrieval-qwen</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>174539434903306044-s15</td>\n",
       "      <td>parametric-gpt</td>\n",
       "      <td>retrieval-gpt</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>174539434903307756-s21</td>\n",
       "      <td>parametric-gemini</td>\n",
       "      <td>retrieval-gemini</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>174539434903307756-s21</td>\n",
       "      <td>parametric-claude</td>\n",
       "      <td>retrieval-gpt</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               session_id                implementation_A  implementation_B  \\\n",
       "0  174539434903306044-s15  agentic-anthropic-web-research  retrieval-claude   \n",
       "1  174539434903306044-s15    agentic-openai-deep-research    retrieval-qwen   \n",
       "2  174539434903306044-s15                  parametric-gpt     retrieval-gpt   \n",
       "3  174539434903307756-s21               parametric-gemini  retrieval-gemini   \n",
       "4  174539434903307756-s21               parametric-claude     retrieval-gpt   \n",
       "\n",
       "  judge judge_swapped  \n",
       "0     A             A  \n",
       "1     A             A  \n",
       "2     A             A  \n",
       "3     A             A  \n",
       "4     B             B  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relative_judge_path = Path(f\"/nlp/data/academic_pdfs/multi_domain_testbed/systems_comparison_relative_judge\")\n",
    "\n",
    "relative_judge_data = []\n",
    "for file in relative_judge_path.glob(\"*.json\"):\n",
    "    with open(file, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    for entry in data:\n",
    "        relative_judge_data.append(entry)\n",
    "relative_judge_df_raw = pd.DataFrame(relative_judge_data)\n",
    "\n",
    "relative_judge_df = relative_judge_df_raw[['session_id', 'implementation_A', 'implementation_B', 'judge', 'judge_swapped']]\n",
    "\n",
    "relative_judge_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7650"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(relative_judge_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_text_to_score(text):\n",
    "    text_to_score = {\n",
    "        'Not at all': 1, \n",
    "        'Barely': 2, \n",
    "        'Moderately': 3, \n",
    "        'Mostly': 4, \n",
    "        'Completely': 5\n",
    "    }\n",
    "    return text_to_score[text]\n",
    "\n",
    "def get_absolute_judge_data_by_id_and_implementation(session_id, field, implementation):\n",
    "    mode = implementation.split('-')[0]\n",
    "    provider = '-'.join(implementation.split('-')[1:])\n",
    "    judge_path = Path(\"/nlp/data/academic_pdfs/multi_domain_testbed/systems_comparison\") / slugify(field) / mode / f\"{provider}_judge_gpt4.1mini.json\"\n",
    "    with open(judge_path, \"r\") as f:\n",
    "        absolute_judge_data_overall = json.load(f)\n",
    "    id_to_absolute_judge_data = {item['corpusid_sectionid']: item for item in absolute_judge_data_overall}\n",
    "    absolute_judge_data = id_to_absolute_judge_data[session_id]\n",
    "    return absolute_judge_data\n",
    "\n",
    "## Runtime: 1.5 minutes\n",
    "id_to_general_domain = {item['id']: item['general_domain'] for item in test_set}\n",
    "\n",
    "id_impl_to_sum_absolute_judge_score = {}\n",
    "for _, session_id, implementation_A, implementation_B in relative_judge_df[['session_id', 'implementation_A', 'implementation_B']].itertuples():\n",
    "    test_data = id_to_test_data[session_id]\n",
    "    general_domain, field = test_data['general_domain'], test_data['field']\n",
    "    absolute_judge_data_A = get_absolute_judge_data_by_id_and_implementation(session_id, field, implementation_A)\n",
    "    absolute_judge_data_B = get_absolute_judge_data_by_id_and_implementation(session_id, field, implementation_B)\n",
    "    id_impl_to_sum_absolute_judge_score[(session_id, implementation_A)] = sum([convert_text_to_score(j['score']) for j in absolute_judge_data_A['rubric_judges_gpt']])\n",
    "    id_impl_to_sum_absolute_judge_score[(session_id, implementation_B)] = sum([convert_text_to_score(j['score']) for j in absolute_judge_data_B['rubric_judges_gpt']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>general_domain</th>\n",
       "      <th>implementation_A</th>\n",
       "      <th>implementation_B</th>\n",
       "      <th>score_A</th>\n",
       "      <th>score_B</th>\n",
       "      <th>leaderboard_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>174539434903306044-s15</td>\n",
       "      <td>Physical &amp; Theoretical Sciences</td>\n",
       "      <td>agentic-anthropic-web-research</td>\n",
       "      <td>retrieval-claude</td>\n",
       "      <td>43</td>\n",
       "      <td>22</td>\n",
       "      <td>win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>174539434903306044-s15</td>\n",
       "      <td>Physical &amp; Theoretical Sciences</td>\n",
       "      <td>agentic-openai-deep-research</td>\n",
       "      <td>retrieval-qwen</td>\n",
       "      <td>46</td>\n",
       "      <td>28</td>\n",
       "      <td>win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>174539434903306044-s15</td>\n",
       "      <td>Physical &amp; Theoretical Sciences</td>\n",
       "      <td>parametric-gpt</td>\n",
       "      <td>retrieval-gpt</td>\n",
       "      <td>33</td>\n",
       "      <td>28</td>\n",
       "      <td>win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>174539434903307756-s21</td>\n",
       "      <td>Physical &amp; Theoretical Sciences</td>\n",
       "      <td>parametric-gemini</td>\n",
       "      <td>retrieval-gemini</td>\n",
       "      <td>36</td>\n",
       "      <td>22</td>\n",
       "      <td>win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>174539434903307756-s21</td>\n",
       "      <td>Physical &amp; Theoretical Sciences</td>\n",
       "      <td>parametric-claude</td>\n",
       "      <td>retrieval-gpt</td>\n",
       "      <td>26</td>\n",
       "      <td>36</td>\n",
       "      <td>lose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7645</th>\n",
       "      <td>174539438544491012-s9</td>\n",
       "      <td>Life &amp; Earth Sciences</td>\n",
       "      <td>agentic-perplexity-web-search</td>\n",
       "      <td>agentic-perplexity-web-search-reasoning</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "      <td>lose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7646</th>\n",
       "      <td>174539438544581152-s1</td>\n",
       "      <td>Life &amp; Earth Sciences</td>\n",
       "      <td>agentic-openai-web-search</td>\n",
       "      <td>agentic-perplexity-web-search-reasoning</td>\n",
       "      <td>38</td>\n",
       "      <td>34</td>\n",
       "      <td>win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7647</th>\n",
       "      <td>174539438544588476-s16</td>\n",
       "      <td>Life &amp; Earth Sciences</td>\n",
       "      <td>agentic-openai-web-search</td>\n",
       "      <td>agentic-perplexity-deep-research</td>\n",
       "      <td>27</td>\n",
       "      <td>39</td>\n",
       "      <td>lose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7648</th>\n",
       "      <td>174539439054783755-s12</td>\n",
       "      <td>Life &amp; Earth Sciences</td>\n",
       "      <td>agentic-anthropic-web-research</td>\n",
       "      <td>agentic-openai-web-search</td>\n",
       "      <td>31</td>\n",
       "      <td>32</td>\n",
       "      <td>lose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7649</th>\n",
       "      <td>174539439054783755-s12</td>\n",
       "      <td>Life &amp; Earth Sciences</td>\n",
       "      <td>agentic-gemini-web-search</td>\n",
       "      <td>retrieval-qwen</td>\n",
       "      <td>25</td>\n",
       "      <td>22</td>\n",
       "      <td>win</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7650 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  session_id                   general_domain  \\\n",
       "0     174539434903306044-s15  Physical & Theoretical Sciences   \n",
       "1     174539434903306044-s15  Physical & Theoretical Sciences   \n",
       "2     174539434903306044-s15  Physical & Theoretical Sciences   \n",
       "3     174539434903307756-s21  Physical & Theoretical Sciences   \n",
       "4     174539434903307756-s21  Physical & Theoretical Sciences   \n",
       "...                      ...                              ...   \n",
       "7645   174539438544491012-s9            Life & Earth Sciences   \n",
       "7646   174539438544581152-s1            Life & Earth Sciences   \n",
       "7647  174539438544588476-s16            Life & Earth Sciences   \n",
       "7648  174539439054783755-s12            Life & Earth Sciences   \n",
       "7649  174539439054783755-s12            Life & Earth Sciences   \n",
       "\n",
       "                    implementation_A                         implementation_B  \\\n",
       "0     agentic-anthropic-web-research                         retrieval-claude   \n",
       "1       agentic-openai-deep-research                           retrieval-qwen   \n",
       "2                     parametric-gpt                            retrieval-gpt   \n",
       "3                  parametric-gemini                         retrieval-gemini   \n",
       "4                  parametric-claude                            retrieval-gpt   \n",
       "...                              ...                                      ...   \n",
       "7645   agentic-perplexity-web-search  agentic-perplexity-web-search-reasoning   \n",
       "7646       agentic-openai-web-search  agentic-perplexity-web-search-reasoning   \n",
       "7647       agentic-openai-web-search         agentic-perplexity-deep-research   \n",
       "7648  agentic-anthropic-web-research                agentic-openai-web-search   \n",
       "7649       agentic-gemini-web-search                           retrieval-qwen   \n",
       "\n",
       "      score_A  score_B leaderboard_status  \n",
       "0          43       22                win  \n",
       "1          46       28                win  \n",
       "2          33       28                win  \n",
       "3          36       22                win  \n",
       "4          26       36               lose  \n",
       "...       ...      ...                ...  \n",
       "7645       32       40               lose  \n",
       "7646       38       34                win  \n",
       "7647       27       39               lose  \n",
       "7648       31       32               lose  \n",
       "7649       25       22                win  \n",
       "\n",
       "[7650 rows x 7 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leaderboard_winnder = []\n",
    "for _, session_id, implementation_A, implementation_B, winner_judge, winner_judge_swapped in relative_judge_df.itertuples():\n",
    "\n",
    "    general_domain = id_to_general_domain[session_id]\n",
    "    \n",
    "    score_a = id_impl_to_sum_absolute_judge_score[(session_id, implementation_A)]\n",
    "    score_b = id_impl_to_sum_absolute_judge_score[(session_id, implementation_B)]\n",
    "\n",
    "    assert winner_judge in [\"A\", \"B\"], f\"winner_judge: {winner_judge}\"\n",
    "    assert winner_judge_swapped in [\"A\", \"B\"], f\"winner_judge_swapped: {winner_judge_swapped}\"\n",
    "\n",
    "    if winner_judge == \"A\":\n",
    "        score_a += 5\n",
    "    elif winner_judge == \"B\":\n",
    "        score_b += 5\n",
    "    \n",
    "    if winner_judge_swapped == \"A\":\n",
    "        score_a += 5\n",
    "    elif winner_judge_swapped == \"B\":\n",
    "        score_b += 5\n",
    "\n",
    "    if score_a > score_b:\n",
    "        leaderboard_status = \"win\"  \n",
    "    elif score_a == score_b:\n",
    "        leaderboard_status = \"tie\"\n",
    "    else:\n",
    "        leaderboard_status = \"lose\"\n",
    "    \n",
    "    leaderboard_winnder.append({\n",
    "        \"session_id\": session_id,\n",
    "        \"general_domain\": general_domain,\n",
    "        \"implementation_A\": implementation_A,\n",
    "        \"implementation_B\": implementation_B,\n",
    "        \"score_A\": score_a,\n",
    "        \"score_B\": score_b,\n",
    "        \"leaderboard_status\": leaderboard_status\n",
    "    })\n",
    "\n",
    "leaderboard_winner_df = pd.DataFrame(leaderboard_winnder)\n",
    "leaderboard_winner_df.to_csv(f\"/nlp/data/academic_pdfs/multi_domain_testbed/leaderboard_bootstrap/leaderboard_winner_df.csv\", index=False)\n",
    "\n",
    "leaderboard_winner_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "leaderboard_status\n",
       "win     4378\n",
       "lose    3050\n",
       "tie      222\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leaderboard_winner_df['leaderboard_status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7650"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(leaderboard_winner_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bradley-Terry Model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>general_domain</th>\n",
       "      <th>implementation_A</th>\n",
       "      <th>implementation_B</th>\n",
       "      <th>score_A</th>\n",
       "      <th>score_B</th>\n",
       "      <th>leaderboard_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>174539434903306044-s15</td>\n",
       "      <td>Physical &amp; Theoretical Sciences</td>\n",
       "      <td>agentic-anthropic-web-research</td>\n",
       "      <td>retrieval-claude</td>\n",
       "      <td>43</td>\n",
       "      <td>22</td>\n",
       "      <td>win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>174539434903306044-s15</td>\n",
       "      <td>Physical &amp; Theoretical Sciences</td>\n",
       "      <td>agentic-openai-deep-research</td>\n",
       "      <td>retrieval-qwen</td>\n",
       "      <td>46</td>\n",
       "      <td>28</td>\n",
       "      <td>win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>174539434903306044-s15</td>\n",
       "      <td>Physical &amp; Theoretical Sciences</td>\n",
       "      <td>parametric-gpt</td>\n",
       "      <td>retrieval-gpt</td>\n",
       "      <td>33</td>\n",
       "      <td>28</td>\n",
       "      <td>win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>174539434903307756-s21</td>\n",
       "      <td>Physical &amp; Theoretical Sciences</td>\n",
       "      <td>parametric-gemini</td>\n",
       "      <td>retrieval-gemini</td>\n",
       "      <td>36</td>\n",
       "      <td>22</td>\n",
       "      <td>win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>174539434903307756-s21</td>\n",
       "      <td>Physical &amp; Theoretical Sciences</td>\n",
       "      <td>parametric-claude</td>\n",
       "      <td>retrieval-gpt</td>\n",
       "      <td>26</td>\n",
       "      <td>36</td>\n",
       "      <td>lose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15295</th>\n",
       "      <td>174539438544491012-s9</td>\n",
       "      <td>Life &amp; Earth Sciences</td>\n",
       "      <td>agentic-perplexity-web-search</td>\n",
       "      <td>agentic-perplexity-web-search-reasoning</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "      <td>lose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15296</th>\n",
       "      <td>174539438544581152-s1</td>\n",
       "      <td>Life &amp; Earth Sciences</td>\n",
       "      <td>agentic-openai-web-search</td>\n",
       "      <td>agentic-perplexity-web-search-reasoning</td>\n",
       "      <td>38</td>\n",
       "      <td>34</td>\n",
       "      <td>win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15297</th>\n",
       "      <td>174539438544588476-s16</td>\n",
       "      <td>Life &amp; Earth Sciences</td>\n",
       "      <td>agentic-openai-web-search</td>\n",
       "      <td>agentic-perplexity-deep-research</td>\n",
       "      <td>27</td>\n",
       "      <td>39</td>\n",
       "      <td>lose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15298</th>\n",
       "      <td>174539439054783755-s12</td>\n",
       "      <td>Life &amp; Earth Sciences</td>\n",
       "      <td>agentic-anthropic-web-research</td>\n",
       "      <td>agentic-openai-web-search</td>\n",
       "      <td>31</td>\n",
       "      <td>32</td>\n",
       "      <td>lose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15299</th>\n",
       "      <td>174539439054783755-s12</td>\n",
       "      <td>Life &amp; Earth Sciences</td>\n",
       "      <td>agentic-gemini-web-search</td>\n",
       "      <td>retrieval-qwen</td>\n",
       "      <td>25</td>\n",
       "      <td>22</td>\n",
       "      <td>win</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15300 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   session_id                   general_domain  \\\n",
       "0      174539434903306044-s15  Physical & Theoretical Sciences   \n",
       "1      174539434903306044-s15  Physical & Theoretical Sciences   \n",
       "2      174539434903306044-s15  Physical & Theoretical Sciences   \n",
       "3      174539434903307756-s21  Physical & Theoretical Sciences   \n",
       "4      174539434903307756-s21  Physical & Theoretical Sciences   \n",
       "...                       ...                              ...   \n",
       "15295   174539438544491012-s9            Life & Earth Sciences   \n",
       "15296   174539438544581152-s1            Life & Earth Sciences   \n",
       "15297  174539438544588476-s16            Life & Earth Sciences   \n",
       "15298  174539439054783755-s12            Life & Earth Sciences   \n",
       "15299  174539439054783755-s12            Life & Earth Sciences   \n",
       "\n",
       "                     implementation_A  \\\n",
       "0      agentic-anthropic-web-research   \n",
       "1        agentic-openai-deep-research   \n",
       "2                      parametric-gpt   \n",
       "3                   parametric-gemini   \n",
       "4                   parametric-claude   \n",
       "...                               ...   \n",
       "15295   agentic-perplexity-web-search   \n",
       "15296       agentic-openai-web-search   \n",
       "15297       agentic-openai-web-search   \n",
       "15298  agentic-anthropic-web-research   \n",
       "15299       agentic-gemini-web-search   \n",
       "\n",
       "                              implementation_B  score_A  score_B  \\\n",
       "0                             retrieval-claude       43       22   \n",
       "1                               retrieval-qwen       46       28   \n",
       "2                                retrieval-gpt       33       28   \n",
       "3                             retrieval-gemini       36       22   \n",
       "4                                retrieval-gpt       26       36   \n",
       "...                                        ...      ...      ...   \n",
       "15295  agentic-perplexity-web-search-reasoning       32       40   \n",
       "15296  agentic-perplexity-web-search-reasoning       38       34   \n",
       "15297         agentic-perplexity-deep-research       27       39   \n",
       "15298                agentic-openai-web-search       31       32   \n",
       "15299                           retrieval-qwen       25       22   \n",
       "\n",
       "      leaderboard_status  \n",
       "0                    win  \n",
       "1                    win  \n",
       "2                    win  \n",
       "3                    win  \n",
       "4                   lose  \n",
       "...                  ...  \n",
       "15295               lose  \n",
       "15296                win  \n",
       "15297               lose  \n",
       "15298               lose  \n",
       "15299                win  \n",
       "\n",
       "[15300 rows x 7 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Avoid tie by duplicate all rows, and for the rows of ties, assign a different winner in each duplicate\n",
    "# Step 1: Duplicate all rows\n",
    "df_dup = pd.concat([leaderboard_winner_df, leaderboard_winner_df], ignore_index=True)\n",
    "\n",
    "# Step 2: Identify tie indices from original DataFrame\n",
    "tie_indices = leaderboard_winner_df[leaderboard_winner_df['leaderboard_status'] == 'tie'].index\n",
    "\n",
    "# Step 3: In the duplicated DataFrame:\n",
    "# - First half: model A wins for tie rows\n",
    "# - Second half: model B wins for tie rows\n",
    "\n",
    "# First half (original order)\n",
    "df_dup.loc[tie_indices, 'leaderboard_status'] = 'win'\n",
    "\n",
    "# Second half (duplicated rows)\n",
    "df_dup.loc[tie_indices + len(leaderboard_winner_df), 'leaderboard_status'] = 'lose'\n",
    "\n",
    "# Resulting modeling-ready DataFrame\n",
    "df_dup = df_dup.reset_index(drop=True)\n",
    "df_dup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>agentic-anthropic-web-research</td>\n",
       "      <td>retrieval-claude</td>\n",
       "      <td>model_a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>agentic-openai-deep-research</td>\n",
       "      <td>retrieval-qwen</td>\n",
       "      <td>model_a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>parametric-gpt</td>\n",
       "      <td>retrieval-gpt</td>\n",
       "      <td>model_a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>parametric-gemini</td>\n",
       "      <td>retrieval-gemini</td>\n",
       "      <td>model_a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>parametric-claude</td>\n",
       "      <td>retrieval-gpt</td>\n",
       "      <td>model_b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15295</th>\n",
       "      <td>agentic-perplexity-web-search</td>\n",
       "      <td>agentic-perplexity-web-search-reasoning</td>\n",
       "      <td>model_b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15296</th>\n",
       "      <td>agentic-openai-web-search</td>\n",
       "      <td>agentic-perplexity-web-search-reasoning</td>\n",
       "      <td>model_a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15297</th>\n",
       "      <td>agentic-openai-web-search</td>\n",
       "      <td>agentic-perplexity-deep-research</td>\n",
       "      <td>model_b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15298</th>\n",
       "      <td>agentic-anthropic-web-research</td>\n",
       "      <td>agentic-openai-web-search</td>\n",
       "      <td>model_b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15299</th>\n",
       "      <td>agentic-gemini-web-search</td>\n",
       "      <td>retrieval-qwen</td>\n",
       "      <td>model_a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15300 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              model_a  \\\n",
       "0      agentic-anthropic-web-research   \n",
       "1        agentic-openai-deep-research   \n",
       "2                      parametric-gpt   \n",
       "3                   parametric-gemini   \n",
       "4                   parametric-claude   \n",
       "...                               ...   \n",
       "15295   agentic-perplexity-web-search   \n",
       "15296       agentic-openai-web-search   \n",
       "15297       agentic-openai-web-search   \n",
       "15298  agentic-anthropic-web-research   \n",
       "15299       agentic-gemini-web-search   \n",
       "\n",
       "                                       model_b   winner  \n",
       "0                             retrieval-claude  model_a  \n",
       "1                               retrieval-qwen  model_a  \n",
       "2                                retrieval-gpt  model_a  \n",
       "3                             retrieval-gemini  model_a  \n",
       "4                                retrieval-gpt  model_b  \n",
       "...                                        ...      ...  \n",
       "15295  agentic-perplexity-web-search-reasoning  model_b  \n",
       "15296  agentic-perplexity-web-search-reasoning  model_a  \n",
       "15297         agentic-perplexity-deep-research  model_b  \n",
       "15298                agentic-openai-web-search  model_b  \n",
       "15299                           retrieval-qwen  model_a  \n",
       "\n",
       "[15300 rows x 3 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dup_processed = df_dup.copy()\n",
    "\n",
    "# Rename columns\n",
    "df_dup_processed[\"model_a\"] = df_dup_processed[\"implementation_A\"]\n",
    "df_dup_processed[\"model_b\"] = df_dup_processed[\"implementation_B\"]\n",
    "\n",
    "# Set winner: if status is 'win', then A wins; else B wins\n",
    "df_dup_processed[\"winner\"] = df_dup_processed[\"leaderboard_status\"].apply(\n",
    "    lambda x: \"model_a\" if x == \"win\" else \"model_b\"\n",
    ")\n",
    "\n",
    "# Select the relevant columns\n",
    "df_dup_processed = df_dup_processed[[\"model_a\", \"model_b\", \"winner\"]]\n",
    "df_dup_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, List, Optional, Tuple\n",
    "\n",
    "def compute_bootstrap_bt(\n",
    "    df: pd.DataFrame,\n",
    "    num_round: int,\n",
    "    base: float = 10.0,\n",
    "    scale: float = 400.0,\n",
    "    init_rating: float = 1000.0,\n",
    "    tol: float = 1e-6,\n",
    "    offset: float = 0.0,\n",
    "    anchor_model_and_rating: Optional[Tuple[Any, float]] = None,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Compute bootstrap Bradley-Terry ratings.\"\"\"\n",
    "    \n",
    "    def get_matchups_models(df: pd.DataFrame) -> Tuple[np.ndarray, List[Any]]:\n",
    "        n_rows = len(df)\n",
    "        model_indices, models = pd.factorize(pd.concat([df[\"model_a\"], df[\"model_b\"]]))\n",
    "        matchups = np.column_stack([model_indices[:n_rows], model_indices[n_rows:]])\n",
    "        return matchups, models.to_list()\n",
    "\n",
    "    def preprocess_for_bt(df: pd.DataFrame) -> Tuple[np.ndarray, np.ndarray, List[Any], np.ndarray]:\n",
    "        n_rows = len(df)\n",
    "        schedule = np.full((n_rows, 3), fill_value=1, dtype=np.int32)\n",
    "        schedule[:, [0, 1]], models = get_matchups_models(df)\n",
    "        schedule[df[\"winner\"] == \"model_a\", 2] = 2\n",
    "        schedule[df[\"winner\"] == \"model_b\", 2] = 0\n",
    "        matchups_outcomes, weights = np.unique(schedule, return_counts=True, axis=0)\n",
    "        matchups = matchups_outcomes[:, [0, 1]]\n",
    "        outcomes = matchups_outcomes[:, 2].astype(np.float64) / 2.0\n",
    "        weights = weights.astype(np.float64)\n",
    "        return matchups, outcomes, models, weights\n",
    "\n",
    "    def bt_loss_and_grad(\n",
    "        ratings: np.ndarray,\n",
    "        matchups: np.ndarray,\n",
    "        outcomes: np.ndarray,\n",
    "        weights: np.ndarray,\n",
    "        alpha: float = 1.0\n",
    "    ) -> Tuple[float, np.ndarray]:\n",
    "        matchup_ratings = ratings[matchups]\n",
    "        logits = alpha * (matchup_ratings[:, 0] - matchup_ratings[:, 1])\n",
    "        probs = 1 / (1 + np.exp(-logits))\n",
    "        loss = -((np.log(probs) * outcomes + np.log(1.0 - probs) * (1.0 - outcomes)) * weights).sum()\n",
    "        matchups_grads = -alpha * (outcomes - probs) * weights\n",
    "        model_grad = np.zeros_like(ratings)\n",
    "        np.add.at(model_grad, matchups[:, [0, 1]], matchups_grads[:, None] * np.array([1.0, -1.0]))\n",
    "        return loss, model_grad\n",
    "\n",
    "    def fit_bt(matchups, outcomes, weights, n_models, alpha, tol=1e-6):\n",
    "        from scipy.optimize import minimize\n",
    "        initial_ratings = np.zeros(n_models, dtype=np.float64)\n",
    "        result = minimize(\n",
    "            fun=bt_loss_and_grad,\n",
    "            x0=initial_ratings,\n",
    "            args=(matchups, outcomes, weights, alpha),\n",
    "            jac=True,\n",
    "            method=\"L-BFGS-B\",\n",
    "            options={\"disp\": False, \"maxiter\": 100, \"gtol\": tol},\n",
    "        )\n",
    "        return result[\"x\"]\n",
    "\n",
    "    def scale_and_offset(ratings, models, scale, init_rating, anchor_model_and_rating=None):\n",
    "        scaled_ratings = ratings * scale + init_rating\n",
    "        if anchor_model_and_rating:\n",
    "            anchor_model, anchor_rating = anchor_model_and_rating\n",
    "            idx = models.index(anchor_model)\n",
    "            scaled_ratings += anchor_rating - scaled_ratings[idx]\n",
    "        return scaled_ratings\n",
    "\n",
    "    matchups, outcomes, models, weights = preprocess_for_bt(df)\n",
    "    rng = np.random.default_rng(seed=0)\n",
    "    idxs = rng.multinomial(n=len(df), pvals=weights / weights.sum(), size=num_round)\n",
    "    boot_weights = idxs.astype(np.float64) / len(df)\n",
    "\n",
    "    bt_fn = partial(\n",
    "        fit_bt, matchups, outcomes, n_models=len(models), alpha=math.log(base), tol=tol\n",
    "    )\n",
    "\n",
    "    results = [bt_fn(w) for w in boot_weights]\n",
    "    ratings = np.array(results)\n",
    "    scaled_ratings = scale_and_offset(\n",
    "        ratings, models, scale, init_rating + offset, anchor_model_and_rating\n",
    "    )\n",
    "\n",
    "    df_out = pd.DataFrame(scaled_ratings, columns=models)\n",
    "    sorted_cols = df_out.median().sort_values(ascending=False).index\n",
    "    return df_out[sorted_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean ± std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>agentic-perplexity-deep-research</th>\n",
       "      <td>1505.19</td>\n",
       "      <td>17.07</td>\n",
       "      <td>1505 ± 17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parametric-gemini</th>\n",
       "      <td>1243.88</td>\n",
       "      <td>9.84</td>\n",
       "      <td>1244 ± 10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>agentic-anthropic-web-research</th>\n",
       "      <td>1148.60</td>\n",
       "      <td>9.61</td>\n",
       "      <td>1149 ± 10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>agentic-openai-deep-research</th>\n",
       "      <td>1144.63</td>\n",
       "      <td>9.71</td>\n",
       "      <td>1145 ± 10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>agentic-perplexity-web-search-reasoning</th>\n",
       "      <td>1114.68</td>\n",
       "      <td>9.52</td>\n",
       "      <td>1115 ± 10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parametric-claude</th>\n",
       "      <td>1099.17</td>\n",
       "      <td>9.40</td>\n",
       "      <td>1099 ± 9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parametric-gpt</th>\n",
       "      <td>1080.48</td>\n",
       "      <td>8.58</td>\n",
       "      <td>1080 ± 9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parametric-qwen</th>\n",
       "      <td>1037.58</td>\n",
       "      <td>8.85</td>\n",
       "      <td>1038 ± 9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>retrieval-gpt</th>\n",
       "      <td>1019.68</td>\n",
       "      <td>8.82</td>\n",
       "      <td>1020 ± 9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>retrieval-qwen</th>\n",
       "      <td>1010.93</td>\n",
       "      <td>9.02</td>\n",
       "      <td>1011 ± 9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>agentic-openai-web-search</th>\n",
       "      <td>992.32</td>\n",
       "      <td>8.81</td>\n",
       "      <td>992 ± 9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>retrieval-claude</th>\n",
       "      <td>971.84</td>\n",
       "      <td>9.07</td>\n",
       "      <td>972 ± 9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>agentic-gemini-web-search</th>\n",
       "      <td>960.23</td>\n",
       "      <td>9.16</td>\n",
       "      <td>960 ± 9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>retrieval-gemini</th>\n",
       "      <td>944.59</td>\n",
       "      <td>9.65</td>\n",
       "      <td>945 ± 10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>agentic-perplexity-web-search</th>\n",
       "      <td>862.27</td>\n",
       "      <td>10.17</td>\n",
       "      <td>862 ± 10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>agentic-openscholar</th>\n",
       "      <td>768.87</td>\n",
       "      <td>11.54</td>\n",
       "      <td>769 ± 12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parametric-llama</th>\n",
       "      <td>616.95</td>\n",
       "      <td>12.83</td>\n",
       "      <td>617 ± 13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>retrieval-openscholar</th>\n",
       "      <td>478.11</td>\n",
       "      <td>16.79</td>\n",
       "      <td>478 ± 17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           mean   std mean ± std\n",
       "agentic-perplexity-deep-research        1505.19 17.07  1505 ± 17\n",
       "parametric-gemini                       1243.88  9.84  1244 ± 10\n",
       "agentic-anthropic-web-research          1148.60  9.61  1149 ± 10\n",
       "agentic-openai-deep-research            1144.63  9.71  1145 ± 10\n",
       "agentic-perplexity-web-search-reasoning 1114.68  9.52  1115 ± 10\n",
       "parametric-claude                       1099.17  9.40   1099 ± 9\n",
       "parametric-gpt                          1080.48  8.58   1080 ± 9\n",
       "parametric-qwen                         1037.58  8.85   1038 ± 9\n",
       "retrieval-gpt                           1019.68  8.82   1020 ± 9\n",
       "retrieval-qwen                          1010.93  9.02   1011 ± 9\n",
       "agentic-openai-web-search                992.32  8.81    992 ± 9\n",
       "retrieval-claude                         971.84  9.07    972 ± 9\n",
       "agentic-gemini-web-search                960.23  9.16    960 ± 9\n",
       "retrieval-gemini                         944.59  9.65   945 ± 10\n",
       "agentic-perplexity-web-search            862.27 10.17   862 ± 10\n",
       "agentic-openscholar                      768.87 11.54   769 ± 12\n",
       "parametric-llama                         616.95 12.83   617 ± 13\n",
       "retrieval-openscholar                    478.11 16.79   478 ± 17"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boot_ratings = compute_bootstrap_bt(df_dup_processed, num_round=1000)\n",
    "\n",
    "# Compute mean and std\n",
    "mean = boot_ratings.mean()\n",
    "std = boot_ratings.std()\n",
    "\n",
    "# Format as \"mean ± std\" string\n",
    "summary_str = mean.map('{:.0f}'.format) + ' ± ' + std.map('{:.0f}'.format)\n",
    "\n",
    "# Combine into a DataFrame\n",
    "summary_df = pd.DataFrame({\n",
    "    'mean': mean,\n",
    "    'std': std,\n",
    "    'mean ± std': summary_str\n",
    "}).sort_values(by='mean', ascending=False)\n",
    "\n",
    "summary_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lsg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
